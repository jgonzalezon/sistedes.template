
@inproceedings{bagawan_develop_2024,
	title = {Develop an {On} - {Device} {LLM} {Android} {Application}},
	issn = {2767-1097},
	url = {https://ieeexplore.ieee.org/document/10816785/},
	doi = {10.1109/CSITSS64042.2024.10816785},
	abstract = {This paper presents the development and implementation of an Android application utilizing a Large Language Model (LLM) that operates directly on the user's device. This approach aims to address the privacy and latency concerns often associated with cloud-based LLM solutions. The application leverages a smaller, optimized LLM, GEMMA 2B, which is capable of running efficiently on mobile hardware. It incorporates a hybrid approach, utilizing on-device processing for specific queries and resorting to cloud-based LLMs for more complex tasks that require extensive knowledge bases. This paper details the system architecture, implementation details, and discusses the performance and challenges encountered during the development process.},
	urldate = {2026-01-15},
	booktitle = {2024 8th {International} {Conference} on {Computational} {System} and {Information} {Technology} for {Sustainable} {Solutions} ({CSITSS})},
	author = {Bagawan, Sohail and G S, Nagaraja},
	month = nov,
	year = {2024},
	note = {ISSN: 2767-1097},
	keywords = {Large language models, Computational modeling, Hardware, Data models, Performance evaluation, Resource management, Privacy, Data privacy, Time factors, Systems architecture, Large Language Model, SQLite, Mobile Computing, Android Application, Cloud Function, GEMMA 2B, Latency, On-device AI},
	pages = {1--5},
	file = {Full Text PDF:files/1156/Bagawan and G S - 2024 - Develop an On - Device LLM Android Application.pdf:application/pdf},
}

@article{wang_empowering_2025,
	title = {Empowering large language models to edge intelligence: {A} survey of edge efficient {LLMs} and techniques},
	volume = {57},
	issn = {15740137},
	shorttitle = {Empowering large language models to edge intelligence},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013725000310},
	doi = {10.1016/j.cosrev.2025.100755},
	abstract = {Large language models (LLMs) have showcased exceptional capabilities across various natural language processing (NLP) tasks in recent years, such as machine translation, text summarization, and question answering. Despite their impressive performance, the deployment of these models on edge devices, such as mobile phones, IoT devices, and edge computing nodes, is significantly hindered by their substantial computational and memory requirements. This survey provides a comprehensive overview of the state-of-the-art techniques and strategies for enabling efficient inference of LLMs on edge devices. We explore approaches including the development of small language models (SLMs), model compression techniques, inference optimization strategies, and dedicated frameworks for edge deployment. Our goal is to highlight the advancements and ongoing challenges in this field, offering valuable insights for researchers and practitioners striving to bring the power of LLMs to edge environments.},
	language = {en},
	urldate = {2026-01-15},
	journal = {Computer Science Review},
	author = {Wang, Rui and Gao, Zhiyong and Zhang, Liuyang and Yue, Shuaibing and Gao, Ziyi},
	month = aug,
	year = {2025},
	pages = {100755},
	file = {PDF:files/1157/Wang et al. - 2025 - Empowering large language models to edge intelligence A survey of edge efficient LLMs and technique.pdf:application/pdf},
}

@article{liu_lightweight_2024,
	title = {Lightweight {Deep} {Learning} for {Resource}-{Constrained} {Environments}: {A} {Survey}},
	volume = {56},
	issn = {0360-0300},
	shorttitle = {Lightweight {Deep} {Learning} for {Resource}-{Constrained} {Environments}},
	url = {https://dl.acm.org/doi/10.1145/3657282},
	doi = {10.1145/3657282},
	abstract = {Over the past decade, the dominance of deep learning has prevailed across various domains of artificial intelligence, including natural language processing, computer vision, and biomedical signal processing. While there have been remarkable improvements in model accuracy, deploying these models on lightweight devices, such as mobile phones and microcontrollers, is constrained by limited resources. In this survey, we provide comprehensive design guidance tailored for these devices, detailing the meticulous design of lightweight models, compression methods, and hardware acceleration strategies. The principal goal of this work is to explore methods and concepts for getting around hardware constraints without compromising the model’s accuracy. Additionally, we explore two notable paths for lightweight deep learning in the future: deployment techniques for TinyML and Large Language Models. Although these paths undoubtedly have potential, they also present significant challenges, encouraging research into unexplored areas.},
	number = {10},
	urldate = {2026-01-15},
	journal = {ACM Comput. Surv.},
	author = {Liu, Hou-I and Galindo, Marco and Xie, Hongxia and Wong, Lai-Kuan and Shuai, Hong-Han and Li, Yung-Hui and Cheng, Wen-Huang},
	month = jun,
	year = {2024},
	pages = {267:1--267:42},
	file = {Full Text PDF:files/1158/Liu et al. - 2024 - Lightweight Deep Learning for Resource-Constrained Environments A Survey.pdf:application/pdf},
}

@article{sammangi_harnessing_nodate,
	title = {Harnessing {Generative} {AI} and {Large} {Language} {Models} for {Revolutionizing}  {Cybersecurity} in the {Internet} of {Things}: {Ethical} and {Privacy} {Implications}},
	abstract = {Generative artificial intelligence (AI) and large language models (LLMs) have in- troduced transformative capabilities in cybersecurity, particularly in securing Internet of Things (IoT) environments. These technologies can synthesize vast datasets, support real-time anomaly detection, and generate predictive insights through simple prompts. However, their deployment also presents ethical and privacy-related concerns, including algorithmic bias, data leakage, and misuse for malicious content creation. This paper conducts a systematic literature review to evaluate how LLMs and generative AI contribute to IoT cybersecurity. We propose an ethical AI-IoT security framework, examine key challenges, and offer recommendations for integrating responsible AI governance. We aim to inform future research, journal editorial practices, and cybersecurity policy discussions around the dual promise and peril of these technologies.},
	language = {en},
	author = {Sammangi, Harsha},
	file = {PDF:files/1210/Sammangi - Harsha Sammangi, Aditya Jagatha and Jun Liu.pdf:application/pdf},
}

@misc{luo_toward_2025,
	title = {Toward {Edge} {General} {Intelligence} with {Multiple}-{Large} {Language} {Model} ({Multi}-{LLM}): {Architecture}, {Trust}, and {Orchestration}},
	shorttitle = {Toward {Edge} {General} {Intelligence} with {Multiple}-{Large} {Language} {Model} ({Multi}-{LLM})},
	url = {http://arxiv.org/abs/2507.00672},
	doi = {10.48550/arXiv.2507.00672},
	abstract = {Edge computing enables real-time data processing closer to its source, thus improving the latency and performance of edge-enabled AI applications. However, traditional AI models often fall short when dealing with complex, dynamic tasks that require advanced reasoning and multimodal data processing. This survey explores the integration of multi-LLMs (Large Language Models) to address this in edge computing, where multiple specialized LLMs collaborate to enhance task performance and adaptability in resource-constrained environments. We review the transition from conventional edge AI models to single LLM deployment and, ultimately, to multi-LLM systems. The survey discusses enabling technologies such as dynamic orchestration, resource scheduling, and cross-domain knowledge transfer that are key for multi-LLM implementation. A central focus is on trusted multi-LLM systems, ensuring robust decision-making in environments where reliability and privacy are crucial. We also present multimodal multi-LLM architectures, where multiple LLMs specialize in handling different data modalities—such as text, images, and audio—by integrating their outputs for comprehensive analysis. Finally, we highlight future directions, including improving resource efficiency, trustworthy governance multi-LLM systems, while addressing privacy, trust, and robustness concerns. This survey provides a valuable reference for researchers and practitioners aiming to leverage multi-LLM systems in edge computing applications.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Luo, Haoxiang and Liu, Yinqiu and Zhang, Ruichen and Wang, Jiacheng and Sun, Gang and Niyato, Dusit and Yu, Hongfang and Xiong, Zehui and Wang, Xianbin and Shen, Xuemin},
	month = jul,
	year = {2025},
	note = {arXiv:2507.00672 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Networking and Internet Architecture},
	file = {PDF:files/1160/Luo et al. - 2025 - Toward Edge General Intelligence with Multiple-Large Language Model (Multi-LLM) Architecture, Trust.pdf:application/pdf},
}

@misc{husom_sustainable_2025,
	title = {Sustainable {LLM} {Inference} for {Edge} {AI}: {Evaluating} {Quantized} {LLMs} for {Energy} {Efficiency}, {Output} {Accuracy}, and {Inference} {Latency}},
	shorttitle = {Sustainable {LLM} {Inference} for {Edge} {AI}},
	url = {http://arxiv.org/abs/2504.03360},
	doi = {10.48550/arXiv.2504.03360},
	abstract = {Deploying Large Language Models (LLMs) on edge devices presents significant challenges due to computational constraints, memory limitations, inference speed, and energy consumption. Model quantization has emerged as a key technique to enable efficient LLM inference by reducing model size and computational overhead. In this study, we conduct a comprehensive analysis of 28 quantized LLMs from the Ollama library, which applies by default Post-Training Quantization (PTQ) and weight-only quantization techniques, deployed on an edge device (Raspberry Pi 4 with 4GB RAM). We evaluate energy efficiency, inference performance, and output accuracy across multiple quantization levels and task types. Models are benchmarked on five standardized datasets (CommonsenseQA, BIG-Bench Hard, TruthfulQA, GSM8K, and HumanEval), and we employ a high-resolution, hardware-based energy measurement tool to capture real-world power consumption. Our findings reveal the trade-offs between energy efficiency, inference speed, and accuracy in different quantization settings, highlighting configurations that optimize LLM deployment for resource-constrained environments. By integrating hardware-level energy profiling with LLM benchmarking, this study provides actionable insights for sustainable AI, bridging a critical gap in existing research on energy-aware LLM deployment.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Husom, Erik Johannes and Goknil, Arda and Astekin, Merve and Shar, Lwin Khin and Kåsen, Andre and Sen, Sagar and Mithassel, Benedikt Andreas and Soylu, Ahmet},
	month = apr,
	year = {2025},
	note = {arXiv:2504.03360 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Computers and Society},
	annote = {Comment: 30 pages, 14 figures},
	annote = {Comment: 30 pages, 14 figures},
	file = {PDF:files/1162/Husom et al. - 2025 - Sustainable LLM Inference for Edge AI Evaluating Quantized LLMs for Energy Efficiency, Output Accur.pdf:application/pdf},
}

@misc{lin_pushing_2025,
	title = {Pushing {Large} {Language} {Models} to the {6G} {Edge}: {Vision}, {Challenges}, and {Opportunities}},
	shorttitle = {Pushing {Large} {Language} {Models} to the {6G} {Edge}},
	url = {http://arxiv.org/abs/2309.16739},
	doi = {10.48550/arXiv.2309.16739},
	abstract = {Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing artificial intelligence (AI) and shaping our society. However, the status quo cloud-based LLM deployment faces critical challenges such as long response time and privacy violation, while on-device LLM deployment is hindered by the limited capabilities of end devices. To address these issues, this article explores the transformative potential of deploying LLMs at the 6G edge. We first introduce killer applications to exemplify the urgent need for edge LLM deployment. Meanwhile, we identify the inherent limitations of on-device LLM deployment. We therefore argue that end-edge cooperation at the 6G edge is a promising solution for the dilemma. Towards this end, we elaborate on the 6G MEC architecture tailored for LLMs. Furthermore, we delve into edge training and edge inference for LLMs, with a focus on end-edge cooperation. In both aspects, we discuss a spectrum of cutting-edge techniques, including split learning/inference, parameter-efficient fine-tuning, parameter-sharing inference, and small-large language model cooperation. Finally, we investigate open problems in green and privacy-preserving edge LLM deployment. This work provides a comprehensive and forward-looking perspective and pathways for enabling LLM deployment at the network edge.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Lin, Zheng and Qu, Guanqiao and Chen, Qiyuan and Chen, Xianhao and Chen, Zhe and Huang, Kaibin},
	month = jun,
	year = {2025},
	note = {arXiv:2309.16739 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 7 pages, 5 figures},
	annote = {Comment: 7 pages, 5 figures},
	file = {PDF:files/1164/Lin et al. - 2025 - Pushing Large Language Models to the 6G Edge Vision, Challenges, and Opportunities.pdf:application/pdf},
}

@misc{tan_mobilequant_2024,
	title = {{MobileQuant}: {Mobile}-friendly {Quantization} for {On}-device {Language} {Models}},
	shorttitle = {{MobileQuant}},
	url = {http://arxiv.org/abs/2408.13933},
	doi = {10.48550/arXiv.2408.13933},
	abstract = {Large language models (LLMs) have revolutionized language processing, delivering outstanding results across multiple applications. However, deploying LLMs on edge devices poses several challenges with respect to memory, energy, and compute costs, limiting their widespread use in devices such as mobile phones. A promising solution is to reduce the number of bits used to represent weights and activations. While existing works have found partial success at quantizing LLMs to lower bitwidths, e.g. 4-bit weights, quantizing activations beyond 16 bits often leads to large computational overheads due to poor on-device quantization support, or a considerable accuracy drop. Yet, 8-bit activations are very attractive for on-device deployment as they would enable LLMs to fully exploit mobile-friendly hardware, e.g. Neural Processing Units (NPUs). In this work, we make a first attempt to facilitate the on-device deployment of LLMs using integer-only quantization. We first investigate the limitations of existing quantization methods for on-device deployment, with a special focus on activation quantization. We then address these limitations by introducing a simple post-training quantization method, named MobileQuant, that extends previous weight equivalent transformation works by jointly optimizing the weight transformation and activation range parameters in an end-to-end manner. MobileQuant demonstrates superior capabilities over existing methods by 1) achieving nearlossless quantization on a wide range of LLM benchmarks, 2) reducing latency and energy consumption by 20\%-50\% compared to current on-device quantization strategies, 3) requiring limited compute budget, 4) being compatible with mobile-friendly compute units, e.g. NPU.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Tan, Fuwen and Lee, Royson and Dudziak, {\L}ukasz and Hu, Shell Xu and Bhattacharya, Sourav and Hospedales, Timothy and Tzimiropoulos, Georgios and Martinez, Brais},
	month = oct,
	year = {2024},
	note = {arXiv:2408.13933 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: EMNLP 2024 Findings. Code and models available: https://github.com/saic-fi/MobileQuant},
	annote = {Comment: EMNLP 2024 Findings. Code and models available: https://github.com/saic-fi/MobileQuant},
	file = {PDF:files/1168/Tan et al. - 2024 - MobileQuant Mobile-friendly Quantization for On-device Language Models.pdf:application/pdf},
}

@misc{liu_mobilellm_2024,
	title = {{MobileLLM}: {Optimizing} {Sub}-billion {Parameter} {Language} {Models} for {On}-{Device} {Use} {Cases}},
	shorttitle = {{MobileLLM}},
	url = {http://arxiv.org/abs/2402.14905},
	doi = {10.48550/arXiv.2402.14905},
	abstract = {This paper addresses the growing need for efficient large language models (LLMs) on mobile devices, driven by increasing cloud costs and latency concerns. We focus on designing top-quality LLMs with fewer than a billion parameters, a practical choice for mobile deployment. Contrary to prevailing belief emphasizing the pivotal role of data and parameter quantity in determining model quality, our investigation underscores the significance of model architecture for sub-billion scale LLMs. Leveraging deep and thin architectures, coupled with embedding sharing and grouped-query attention mechanisms, we establish a strong baseline network denoted as MobileLLM, which attains a remarkable 2.7\%/4.3\% accuracy boost over preceding 125M/350M state-of-the-art models. Additionally, we propose an immediate block-wise weightsharing approach with no increase in model size and only marginal latency overhead. The resultant models, denoted as MobileLLM-LS, demonstrate a further accuracy enhancement of 0.7\%/0.8\% than MobileLLM 125M/350M. Moreover, MobileLLM model family shows significant improvements compared to previous subbillion models on chat benchmarks, and demonstrates close correctness to LLaMA-v2 7B in API calling tasks, highlighting the capability of small models for common on-device use cases.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Liu, Zechun and Zhao, Changsheng and Iandola, Forrest and Lai, Chen and Tian, Yuandong and Fedorov, Igor and Xiong, Yunyang and Chang, Ernie and Shi, Yangyang and Krishnamoorthi, Raghuraman and Lai, Liangzhen and Chandra, Vikas},
	month = jun,
	year = {2024},
	note = {arXiv:2402.14905 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: ICML 2024. Code is available at https://github.com/facebookresearch/MobileLLM},
	annote = {Comment: ICML 2024. Code is available at https://github.com/facebookresearch/MobileLLM},
	file = {PDF:files/1171/Liu et al. - 2024 - MobileLLM Optimizing Sub-billion Parameter Language Models for On-Device Use Cases.pdf:application/pdf},
}

@article{yuan_llm-driven_2025,
	title = {{LLM}-{Driven} {Offloading} {Decisions} for {Edge} {Object} {Detection} in {Smart} {City} {Deployments}},
	volume = {8},
	issn = {2624-6511},
	url = {https://www.mdpi.com/2624-6511/8/5/169},
	doi = {10.3390/smartcities8050169},
	abstract = {Object detection is a critical technology for smart city development. As request volumes surge, inference is increasingly offloaded from centralized clouds to user-proximal edge sites to reduce latency and backhaul traffic. However, heterogeneous workloads, fluctuating bandwidth, and dynamic device capabilities make offloading and scheduling difficult to optimize in edge environments. Deep reinforcement learning (DRL) has proved effective for this problem, but in practice, it relies on manually engineered reward functions that must be redesigned whenever service objectives change. To address this limitation, we introduce an LLM-driven framework that retargets DRL policies for edge object detection directly through natural language instructions. By leveraging understanding of the text and encoding capabilities of large language models (LLMs), our system (i) interprets the current optimization objective; (ii) generates an executable, environment-compatible reward function code; and (iii) iteratively refines the reward via closed-loop simulation feedback. In simulations for a real-world dataset, policies trained with LLM-generated rewards adapt from prompts alone and outperform counterparts trained with expert-designed rewards, while eliminating manual reward engineering.},
	language = {en},
	number = {5},
	urldate = {2026-01-08},
	journal = {Smart Cities},
	author = {Yuan, Xingyu and Li, He},
	month = oct,
	year = {2025},
	pages = {169},
	file = {PDF:files/1173/Yuan y Li - 2025 - LLM-Driven Offloading Decisions for Edge Object Detection in Smart City Deployments.pdf:application/pdf},
}

@inproceedings{li_large_2024,
	address = {Minato-ku Tokyo Japan},
	title = {Large {Language} {Models} on {Mobile} {Devices}: {Measurements}, {Analysis}, and {Insights}},
	isbn = {979-8-4007-0663-9},
	shorttitle = {Large {Language} {Models} on {Mobile} {Devices}},
	url = {https://dl.acm.org/doi/10.1145/3662006.3662059},
	doi = {10.1145/3662006.3662059},
	abstract = {Deploying large language models (LLMs) inference into mobile devices is cost-efficient for companies, and well addresses the privacy concern of users. However, the limited computation capacity and memory constraints of mobile devices hinder their practical deployment. Prior work strives to expand model size for better accuracy performance, while there is a lack of systematic understanding of "small" sub-10 billion LLMs that are already feasible for current commodity devices. To better reveal the current landscape of LLMs on mobile devices, we conducted a comprehensive measurement study, deploying 22 models across 4 mobile devices. Our measurements focus on accuracy, inference latency, and memory footprint across various input lengths, devices, and execution engines. The observations from the measurements point us toward promising directions for efficient LLM deployment on mobile devices.},
	language = {en},
	urldate = {2026-01-08},
	booktitle = {Proceedings of the {Workshop} on {Edge} and {Mobile} {Foundation} {Models}},
	publisher = {ACM},
	author = {Li, Xiang and Lu, Zhenyan and Cai, Dongqi and Ma, Xiao and Xu, Mengwei},
	month = jun,
	year = {2024},
	pages = {1--6},
	file = {PDF:files/1176/Li et al. - 2024 - Large Language Models on Mobile Devices Measurements, Analysis, and Insights.pdf:application/pdf},
}

@inproceedings{hadish_language_2024,
	address = {Dubai, United Arab Emirates},
	title = {Language {Models} at the {Edge}: {A} {Survey} on {Techniques}, {Challenges}, and {Applications}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-5479-9},
	shorttitle = {Language {Models} at the {Edge}},
	url = {https://ieeexplore.ieee.org/document/10852473/},
	doi = {10.1109/FLLM63129.2024.10852473},
	abstract = {The invention of the transformer architectures has spurred Large Language Models (LLMs) to the forefront of artificial intelligence, driving state-of-the-art advancements across various domains. However, the huge scale of these models, often comprising hundreds of billions of parameters, presents significant challenges in terms of computational resources for both training and deployment. Consequently, the development and implementation of LLMs have largely been confined to major technology corporations. Recent research has focused on addressing these limitations by developing compact LLMs capable of operating on edge devices, rather than relying on centralized server infrastructure. This approach offers numerous benefits, including reduced computational costs, lower latency, enhanced security, and the potential for task-specific, specialized models. This paper examines the latest research trends and developments in the field of compact LLMs, exploring their applications and discussing the challenges associated with their implementation. Our investigation aims to provide insights into the future landscape of accessible and efficient language models.},
	language = {en},
	urldate = {2026-01-08},
	booktitle = {2024 2nd {International} {Conference} on {Foundation} and {Large} {Language} {Models} ({FLLM})},
	publisher = {IEEE},
	author = {Hadish, Siem and Bojković, Velibor and Aloqaily, Moayad and Guizani, Mohsen},
	month = nov,
	year = {2024},
	pages = {262--271},
	file = {PDF:files/1178/Hadish et al. - 2024 - Language Models at the Edge A Survey on Techniques, Challenges, and Applications.pdf:application/pdf},
}

@misc{chai_flexquant_2025,
	title = {{FlexQuant}: {Elastic} {Quantization} {Framework} for {Locally} {Hosted} {LLM} on {Edge} {Devices}},
	shorttitle = {{FlexQuant}},
	url = {http://arxiv.org/abs/2501.07139},
	doi = {10.48550/arXiv.2501.07139},
	abstract = {Deploying LLMs on edge devices presents serious technical challenges. Memory elasticity is crucial for edge devices with unified memory, where memory is shared and fluctuates dynamically. Existing solutions suffer from either poor transition granularity or high storage costs. We propose FlexQuant, a novel elasticity framework that generates an ensemble of quantized models, providing an elastic hosting solution with 15x granularity improvement and 10x storage reduction compared to SoTA methods. FlexQuant works with most quantization methods and creates a family of trade-off options under various storage limits through our pruning method. It brings great performance and flexibility to the edge deployment of LLMs.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Chai, Yuji and Kwen, Mujin and Brooks, David and Wei, Gu-Yeon},
	month = jan,
	year = {2025},
	note = {arXiv:2501.07139 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Performance},
	file = {PDF:files/1180/Chai et al. - 2025 - FlexQuant Elastic Quantization Framework for Locally Hosted LLM on Edge Devices.pdf:application/pdf},
}

@misc{qin_empirical_2024,
	title = {Empirical {Guidelines} for {Deploying} {LLMs} onto {Resource}-constrained {Edge} {Devices}},
	url = {http://arxiv.org/abs/2406.03777},
	doi = {10.48550/arXiv.2406.03777},
	abstract = {The scaling laws have become the de facto guidelines for designing large language models (LLMs), but they were studied under the assumption of unlimited computing resources for both training and inference. As LLMs are increasingly used as personalized intelligent assistants, their customization (i.e., learning through finetuning) and deployment onto resource-constrained edge devices will become more and more prevalent. An urgent but open question is how a resource-constrained computing environment would affect the design choices for a personalized LLM. We study this problem empirically in this work. In particular, we consider the tradeoffs among a number of key design factors and their intertwined impacts on learning efficiency and accuracy. The factors include the learning methods for LLM customization, the amount of personalized data used for learning customization, the types and sizes of LLMs, the compression methods of LLMs, the amount of time afforded to learn, and the difficulty levels of the target use cases. Through extensive experimentation and benchmarking, we draw a number of surprisingly insightful guidelines for deploying LLMs onto resource-constrained devices. For example, an optimal choice between parameter learning and RAG may vary depending on the difficulty of the downstream task, the longer fine-tuning time does not necessarily help the model, and a compressed LLM may be a better choice than an uncompressed LLM to learn from limited personalized data.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Qin, Ruiyang and Liu, Dancheng and Xu, Chenhui and Yan, Zheyu and Tan, Zhaoxuan and Jia, Zhenge and Nassereldine, Amir and Li, Jiajie and Jiang, Meng and Abbasi, Ahmed and Xiong, Jinjun and Shi, Yiyu},
	month = oct,
	year = {2024},
	note = {arXiv:2406.03777 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: Benckmarking paper},
	annote = {Comment: Benckmarking paper},
	file = {PDF:files/1183/Qin et al. - 2024 - Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices.pdf:application/pdf},
}

@misc{yan_are_2025,
	title = {Are {We} {There} {Yet}? {A} {Measurement} {Study} of {Efficiency} for {LLM} {Applications} on {Mobile} {Devices}},
	shorttitle = {Are {We} {There} {Yet}?},
	url = {http://arxiv.org/abs/2504.00002},
	doi = {10.48550/arXiv.2504.00002},
	abstract = {Recent advancements in large language models (LLMs) have prompted interest in deploying these models on mobile devices to enable new applications without relying on cloud connectivity. However, the efficiency constraints of deploying LLMs on resource-limited devices present significant challenges. In this paper, we conduct a comprehensive measurement study to evaluate the efficiency tradeoffs between mobile-based, edge-based, and cloud-based deployments for LLM applications. We implement AutoLife-Lite, a simplified LLM-based application that analyzes smartphone sensor data to infer user location and activity contexts. Our experiments reveal that: (1) Only small-size LLMs ({\textless}4B parameters) can run successfully on powerful mobile devices, though they exhibit quality limitations compared to larger models; (2) Model compression is effective in lower the hardware requirement, but may lead to significant performance degradation; (3) The latency to run LLMs on mobile devices with meaningful output is significant ({\textgreater}30 seconds), while cloud services demonstrate better time efficiency ({\textless}10 seconds); (4) Edge deployments offer intermediate tradeoffs between latency and model capabilities, with different results on CPU-based and GPU-based settings. These findings provide valuable insights for system designers on the current limitations and future directions for on-device LLM applications.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Yan, Xiao and Ding, Yi},
	month = mar,
	year = {2025},
	note = {arXiv:2504.00002 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Networking and Internet Architecture, Computer Science - Performance, Computer Science - Human-Computer Interaction},
	file = {PDF:files/1185/Yan y Ding - 2025 - Are We There Yet A Measurement Study of Efficiency for LLM Applications on Mobile Devices.pdf:application/pdf},
}

@inproceedings{baccour_active_2025,
	address = {Milan, Italy},
	title = {Active {Prompt} {Caching} in {Edge} {Networks} for {Generative} {AI} and {LLMs}: {An} {RL}-{Based} {Approach}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-6836-9},
	shorttitle = {Active {Prompt} {Caching} in {Edge} {Networks} for {Generative} {AI} and {LLMs}},
	url = {https://ieeexplore.ieee.org/document/10978306/},
	doi = {10.1109/WCNC61545.2025.10978306},
	abstract = {Generative AI (GAI) and Large Language Models (LLMs) have revolutionized natural language processing and content creation. However, their signiﬁcant computational demands during inference often require cloud servers, which are currently the only viable option for handling complex multi-modal models like GPT-4. The inherent complexity of these models increases latency, posing challenges even within cloud environments. Furthermore, cloud reliance brings other challenges, including high bandwidth consumption to transfer diverse data types. Worse, in personalized GAI applications like virtual assistants, similar prompts frequently occur, causing redundant transmission and computation of replies, which further increases overhead. Accelerating the inference of multi-modal systems is, therefore, critical in artiﬁcial intelligence. In this paper, we aim to improve the inference efﬁciency through prompt caching; if a current prompt is semantically similar to a previous one, the system can reuse the earlier response without invoking the model again. We leverage collaborative edge computing to cache popular replies and store their request embeddings. New prompts are locally processed to extract embeddings, with their qualities determined by the resources available on edge servers. Our problem is formulated as an optimization to manage ofﬂoading decisions for GAI tasks, aiming to avoid cloud inferences and minimize latency while maximizing reply quality. Given its non-convex nature, we propose to solve it via Block Successive Upper Bound Minimization (BSUM). Reinforcement learning is employed to actively pre-cache prompts, tackling the complexity of unknown prompt popularity. Our approach demonstrates near-optimal performance, signiﬁcantly outperforming cloud-only solutions.},
	language = {en},
	urldate = {2026-01-08},
	booktitle = {2025 {IEEE} {Wireless} {Communications} and {Networking} {Conference} ({WCNC})},
	publisher = {IEEE},
	author = {Baccour, Emna and Erbad, Aiman and Mohamed, Amr and Hamdi, Mounir and Guizani, Mohsen},
	month = mar,
	year = {2025},
	pages = {01--07},
	file = {PDF:files/1187/Baccour et al. - 2025 - Active Prompt Caching in Edge Networks for Generative AI and LLMs An RL-Based Approach.pdf:application/pdf},
}

@misc{zheng_review_2025,
	title = {A {Review} on {Edge} {Large} {Language} {Models}: {Design}, {Execution}, and {Applications}},
	shorttitle = {A {Review} on {Edge} {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2410.11845},
	doi = {10.48550/arXiv.2410.11845},
	abstract = {YUE ZHENG, Zhejiang University of Technology, China YUHAO CHEN, Zhejiang University, China BIN QIAN, Zhejiang University, China XIUFANG SHI, Zhejiang University of Technology, China YUANCHAO SHU∗, Zhejiang University, China JIMING CHEN∗, Zhejiang University, China Large language models (LLMs) have revolutionized natural language processing with their exceptional understanding, synthesizing, and reasoning capabilities. However, deploying LLMs on resourceconstrained edge devices presents signiﬁcant challenges due to computational limitations, memory constraints, and edge hardware heterogeneity. This survey provides a comprehensive overview of recent advancements in edge LLMs, covering the entire lifecycle — from resource-efﬁcient model design and pre-deployment strategies to runtime inference optimizations. It also explores on-device applications across various domains. By synthesizing state-of-the-art techniques and identifying future research directions, this survey bridges the gap between the immense potential of LLMs and the constraints of edge computing. CCS Concepts: • Computing methodologies → Artiﬁcial intelligence; • Computer systems organization → Embedded and cyber-physical systems; • Human-centered computing → Ubiquitous and mobile computing.},
	language = {en},
	urldate = {2026-01-08},
	publisher = {arXiv},
	author = {Zheng, Yue and Chen, Yuhao and Qian, Bin and Shi, Xiufang and Shu, Yuanchao and Chen, Jiming},
	month = feb,
	year = {2025},
	note = {arXiv:2410.11845 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: Accepted by ACM Computing Surveys(CSUR)},
	annote = {Comment: Accepted by ACM Computing Surveys(CSUR)},
	annote = {Comment: Accepted by ACM Computing Surveys(CSUR)},
	file = {PDF:files/1191/Zheng et al. - 2025 - A Review on Edge Large Language Models Design, Execution, and Applications.pdf:application/pdf},
}

@article{northeastern_university_boston_ma_review_2025,
	title = {A {Review} of {Large} {Language} {Models} in {Edge} {Computing}: {Applications}, {Challenges}, {Benefits}, and {Deployment} {Strategies}},
	volume = {05},
	issn = {26925141},
	shorttitle = {A {Review} of {Large} {Language} {Models} in {Edge} {Computing}},
	url = {https://www.academicpublishers.org/journals/index.php/ijdsml/article/view/5302/6234},
	doi = {10.55640/ijdsml-05-01-25},
	abstract = {Large Language Models (LLMs) have achieved very good success in natural language processing, but deployment of these powerful models on edge computing devices across all domains presents unique challenges. This paper reviews the state of LLMs in edge computing, focusing on four key aspects: their emerging applications across various sectors, the technical challenges of running LLMs on resource-constrained edge devices, the potential benefits of bringing LLM capabilities closer to data sources, and effective deployment strategies to enable LLMs at the edge. We also discuss on how LLM edge deployment could offer low-latency, privacy-preserving intelligent assistance throughout a range of domains, such as healthcare, IoT, industrial automation, and more. We also look at some techniques and architectures that can overcome the limitations of edge devices, such as cloud-edge collaboration, federated learning, model compression, and on-device inference. This review identifies practical ways to integrate LLMs into edge environments by examining current practices and their trade-offs. It also provides guidance for future research to address the remaining issues in this quickly expanding field.},
	language = {en},
	number = {01},
	urldate = {2026-01-08},
	journal = {International journal of data science and machine learning},
	author = {{Northeastern University, Boston, MA} and Kompally, Venkata Srinivas},
	month = jun,
	year = {2025},
	pages = {300--322},
	file = {PDF:files/1194/Northeastern University, Boston, MA y Kompally - 2025 - A Review of Large Language Models in Edge Computing Applications, Challenges, Benefits, and Deploym.pdf:application/pdf},
}

@article{picano_matching_2025,
	title = {A {Matching} {Game} for {LLM} {Layer} {Deployment} in {Heterogeneous} {Edge} {Networks}},
	volume = {6},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2644-125X},
	url = {https://ieeexplore.ieee.org/document/10966456/},
	doi = {10.1109/OJCOMS.2025.3561605},
	abstract = {With the growing demand for computational and storage capabilities of modern learning models, performing their computation exclusively in a centralized manner has become increasingly impractical. Executing the inference of foundation models in a distributed manner presents significant challenges, particularly in optimizing both computing and communication resources. This work introduces a novel deployment scheme for large language model (LLM) layers that jointly considers computation and communication efficiency within an edge network environment to address these issues. Specifically, we resort to the matching theory to effectively orchestrate the distributed deployment of the LLM layers across the edge nodes of the networks, where nodes have varying computational capacities and communication speed. This framework is based on a two-sided game, enabling each layer to express its individual preferences for node allocation while allowing nodes to prioritize their preferred layers. This mutual selection process minimizes inference latency in the learning process and models the bubble time as game externalities, assuming a sequential pipeline execution. The algorithmic solution reaches a stable matching outcome. Performance evaluation was conducted considering both simulations and a small-scale testbed to measure the effectiveness of the proposed algorithm compared to state-of-the-art alternatives. In particular, the small-scale testbed was developed to distribute an LLM to support autonomous driving, leveraging the vision-language model paradigm. The results highlight performance improvements of up to around 10\% in comparison to the Koklata game alternative.},
	language = {en},
	urldate = {2026-01-08},
	journal = {IEEE Open Journal of the Communications Society},
	author = {Picano, Benedetta and Hoang, Dinh Thai and Nguyen, Diep N.},
	year = {2025},
	pages = {3795--3805},
	file = {PDF:files/1195/Picano et al. - 2025 - A Matching Game for LLM Layer Deployment in Heterogeneous Edge Networks.pdf:application/pdf},
}

@article{pozi_data-augmented_2025,
	title = {A data-augmented model routing framework for efficient {LLM} deployment in edge–cloud environments},
	volume = {81},
	issn = {1573-0484},
	url = {https://link.springer.com/10.1007/s11227-025-08034-8},
	doi = {10.1007/s11227-025-08034-8},
	abstract = {Large language model (LLM)-based program generation tasks are hindered by high computational demands. These challenges, along with high deployment costs, often pose a barrier to practical applications. To address these, we propose a novel data-augmented multi-LLM model routing approach that classifies prompts based on whether they should be processed on a weak LLM engine or a strong LLM. Experimental results show up to 16 times better efficiency compared to the existing cascaded approaches, while preserving the inference accuracy. Thus, the proposed method optimally allocates prompts across multiple LLMs, reducing computational costs while maintaining inference accuracy.},
	language = {en},
	number = {17},
	urldate = {2026-01-08},
	journal = {The Journal of Supercomputing},
	author = {Pozi, Muhammad Syafiq Mohd and Sato, Yukinori},
	month = nov,
	year = {2025},
	pages = {1573},
	file = {PDF:files/1197/Pozi y Sato - 2025 - A data-augmented model routing framework for efficient LLM deployment in edge–cloud environments.pdf:application/pdf},
}

@article{alipio_role_2025,
	title = {The {Role} of {Large} {Language} {Models} in {Designing} {Reliable} {Networks} for {Internet} of {Things}: {A} {Short} {Review} of {Most} {Recent} {Developments}},
	volume = {13},
	issn = {2169-3536},
	shorttitle = {The {Role} of {Large} {Language} {Models} in {Designing} {Reliable} {Networks} for {Internet} of {Things}},
	url = {https://ieeexplore.ieee.org/document/11179972/},
	doi = {10.1109/ACCESS.2025.3614246},
	abstract = {The rapid growth of Internet of Things (IoT) networks has increased the need for intelligent, flexible, and scalable networking solutions. This paper reviews the use of Large Language Models (LLMs) to improving network protocols, automate decision-making, and strengthen security in IoT networks. A detailed analysis was conducted to classify the existing research based on applications, network types, methodologies, and performance metrics. LLMs have been used in network configuration, security monitoring, cyber threat detection, federated learning, and for improving network performance. Their integration with edge computing, 6G networks, and AI-driven network control enables real-time network adjustment, automated troubleshooting, and efficient traffic management. However, challenges such as high computing demands, high energy consumption, security risks, and slow adaptation in dynamic networks still exist. This study identifies emerging trends, including LLM-based self-learning networks, privacy-aware AI training, and hybrid AI models that combine graph-based neural networks, reinforcement learning, and multimodal AI. By reviewing recent research from 2023 to early-2025, this study provides a clear understanding of how LLMs transform the IoT and network management. The discussion highlights future research directions, focusing on decentralized AI frameworks, optimized model training, and AI-driven network automation, with the aim of developing more efficient, secure, and reliable network infrastructures.},
	urldate = {2026-01-14},
	journal = {IEEE Access},
	author = {Alipio, Melchizedek and Bures, Miroslav},
	year = {2025},
	keywords = {Large language models, Real-time systems, Computational modeling, Internet of Things, Reliability, Biological system modeling, Artificial intelligence, Reviews, machine learning, Protocols, Adaptation models, Security, network optimization, reliable networks},
	pages = {168527--168545},
	file = {Full Text PDF:files/1199/Alipio and Bures - 2025 - The Role of Large Language Models in Designing Reliable Networks for Internet of Things A Short Rev.pdf:application/pdf},
}

@misc{amini_distributed_2025,
	title = {Distributed {LLMs} and {Multimodal} {Large} {Language} {Models}: {A} {Survey} on {Advances}, {Challenges}, and {Future} {Directions}},
	shorttitle = {Distributed {LLMs} and {Multimodal} {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2503.16585},
	doi = {10.48550/arXiv.2503.16585},
	abstract = {Language models (LMs) are machine learning models designed to predict linguistic patterns by estimating the probability of word sequences based on large-scale datasets, such as text. LMs have a wide range of applications in natural language processing (NLP) tasks, including autocomplete and machine translation. Although larger datasets typically enhance LM performance, scalability remains a challenge due to constraints in computational power and resources. Distributed computing strategies offer essential solutions for improving scalability and managing the growing computational demand. Further, the use of sensitive datasets in training and deployment raises significant privacy concerns. Recent research has focused on developing decentralized techniques to enable distributed training and inference while utilizing diverse computational resources and enabling edge AI. This paper presents a survey on distributed solutions for various LMs, including large language models (LLMs), vision language models (VLMs), multimodal LLMs (MLLMs), and small language models (SLMs). While LLMs focus on processing and generating text, MLLMs are designed to handle multiple modalities of data (e.g., text, images, and audio) and to integrate them for broader applications. To this end, this paper reviews key advancements across the MLLM pipeline, including distributed training, inference, fine-tuning, and deployment, while also identifying the contributions, limitations, and future areas of improvement. Further, it categorizes the literature based on six primary focus areas of decentralization. Our analysis describes gaps in current methodologies for enabling distributed solutions for LMs and outline future research directions, emphasizing the need for novel solutions to enhance the robustness and applicability of distributed LMs.},
	urldate = {2026-01-14},
	publisher = {arXiv},
	author = {Amini, Hadi and Mia, Md Jueal and Saadati, Yasaman and Imteaj, Ahmed and Nabavirazavi, Seyedsina and Thakker, Urmish and Hossain, Md Zarif and Fime, Awal Ahmed and Iyengar, S. S.},
	month = mar,
	year = {2025},
	note = {arXiv:2503.16585 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Full Text PDF:files/1201/Amini et al. - 2025 - Distributed LLMs and Multimodal Large Language Models A Survey on Advances, Challenges, and Future.pdf:application/pdf;Snapshot:files/1200/2503.html:text/html},
}

@misc{khatiwada_large_2025,
	title = {Large {Language} {Models} in the {IoT} {Ecosystem} -- {A} {Survey} on {Security} {Challenges} and {Applications}},
	url = {http://arxiv.org/abs/2505.17586},
	doi = {10.48550/arXiv.2505.17586},
	abstract = {The Internet of Things (IoT) and Large Language Models (LLMs) have been two major emerging players in the information technology era. Although there has been significant coverage of their individual capabilities, our literature survey sheds some light on the integration and interaction of LLMs and IoT devices - a mutualistic relationship in which both parties leverage the capabilities of the other. LLMs like OpenAI's ChatGPT, Anthropic's Claude, Google's Gemini/BERT, any many more, all demonstrate powerful capabilities in natural language understanding and generation, enabling more intuitive and context-aware interactions across diverse IoT applications such as smart cities, healthcare systems, industrial automation, and smart home environments. Despite these opportunities, integrating these resource-intensive LLMs into IoT devices that lack the state-of-the-art computational power is a challenging task. The security of these edge devices is another major concern as they can easily act as a backdoor to private networks if the LLM integration is sloppy and unsecured. This literature survey systematically explores the current state-of-the-art in applying LLMs within IoT, emphasizing their applications in various domains/sectors of society, the significant role they play in enhancing IoT security through anomaly detection and threat mitigation, and strategies for effective deployment using edge computing frameworks. Finally, this survey highlights existing challenges, identifies future research directions, and underscores the need for cross-disciplinary collaboration to fully realize the transformative potential of integrating LLMs and IoT.},
	urldate = {2026-01-14},
	publisher = {arXiv},
	author = {Khatiwada, Kushal and Hopper, Jayden and Cheatham, Joseph and Joshi, Ayan and Baidya, Sabur},
	month = may,
	year = {2025},
	note = {arXiv:2505.17586 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Full Text PDF:files/1203/Khatiwada et al. - 2025 - Large Language Models in the IoT Ecosystem -- A Survey on Security Challenges and Applications.pdf:application/pdf;Snapshot:files/1202/2505.html:text/html},
}

@misc{zhang_toward_2024,
	title = {Toward {Democratized} {Generative} {AI} in {Next}-{Generation} {Mobile} {Edge} {Networks}},
	url = {http://arxiv.org/abs/2411.09148},
	doi = {10.48550/arXiv.2411.09148},
	abstract = {The rapid development of generative AI technologies, including large language models (LLMs), has brought transformative changes to various fields. However, deploying such advanced models on mobile and edge devices remains challenging due to their high computational, memory, communication, and energy requirements. To address these challenges, we propose a model-centric framework for democratizing generative AI deployment on mobile and edge networks. First, we comprehensively review key compact model strategies, such as quantization, model pruning, and knowledge distillation, and present key performance metrics to optimize generative AI for mobile deployment. Next, we provide a focused review of mobile and edge networks, emphasizing the specific challenges and requirements of these environments. We further conduct a case study demonstrating the effectiveness of these strategies by deploying LLMs on real mobile edge devices. Experimental results highlight the practicality of democratized LLMs, with significant improvements in generalization accuracy, hallucination rate, accessibility, and resource consumption. Finally, we discuss potential research directions to further advance the deployment of generative AI in resource-constrained environments.},
	urldate = {2026-01-14},
	publisher = {arXiv},
	author = {Zhang, Ruichen and He, Jiayi and Luo, Xiaofeng and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Li, Yonghui and Sikdar, Biplab},
	month = nov,
	year = {2024},
	note = {arXiv:2411.09148 [cs]},
	keywords = {Computer Science - Networking and Internet Architecture},
	annote = {Comment: 9 pages, 5 figures},
	file = {Full Text PDF:files/1205/Zhang et al. - 2024 - Toward Democratized Generative AI in Next-Generation Mobile Edge Networks.pdf:application/pdf;Snapshot:files/1204/2411.html:text/html},
}

@article{golec_llm-driven_2025,
	title = {{LLM}-{Driven} {APT} {Detection} for {6G} {Wireless} {Networks}: {A} {Systematic} {Review} and {Taxonomy}},
	volume = {13},
	issn = {2169-3536},
	shorttitle = {{LLM}-{Driven} {APT} {Detection} for {6G} {Wireless} {Networks}},
	url = {https://ieeexplore.ieee.org/document/11112774/},
	doi = {10.1109/ACCESS.2025.3595665},
	abstract = {Sixth Generation (6G) wireless networks, which are expected to be deployed in the 2030s, have already created great excitement in academia and the private sector with their extremely high communication speed and low latency rates. However, despite the ultra-low latency, high throughput, and AI-assisted orchestration capabilities they promise, they are vulnerable to stealthy and long-term Advanced Persistent Threats (APTs). Large Language Models (LLMs) stand out as an ideal candidate to fill this gap with their high success in semantic reasoning and threat intelligence. This paper presents the first systematic review and taxonomy for LLM-assisted APT detection in 6G networks. It also provides insights by reviewing recent research on the intersection of LLMs, APTs, and 6G. Key challenges such as limitations in edge deployment, data scarcities, and explainability gaps are identified and a multidimensional taxonomy is provided in line with the APT lifecycle and 6G contexts. The paper is based on 142 studies from 2018 to 2025, searching leading databases such as IEEE Xplore, ACM Digital Library, SpringerLink, and Elsevier ScienceDirect.},
	urldate = {2026-01-14},
	journal = {IEEE Access},
	author = {Golec, Muhammed and Khamayseh, Yaser and Melhem, Suhib Bani and Alwarafy, Abdulmalik},
	year = {2025},
	keywords = {Semantics, Wireless networks, Surveys, Image edge detection, 6G mobile communication, Systematics, large language model (LLM), natural language processing (NLP), security, Systematic literature review, Threat assessment, Taxonomy, 6G wireless networks, advanced persistent threat (APT), Reproducibility of results},
	pages = {145271--145288},
	file = {Full Text PDF:files/1211/Golec et al. - 2025 - LLM-Driven APT Detection for 6G Wireless Networks A Systematic Review and Taxonomy.pdf:application/pdf},
}

@article{kim_efficient_2025,
	title = {Efficient {Compressing} and {Tuning} {Methods} for {Large} {Language} {Models}: {A} {Systematic} {Literature} {Review}},
	volume = {57},
	issn = {0360-0300},
	shorttitle = {Efficient {Compressing} and {Tuning} {Methods} for {Large} {Language} {Models}},
	url = {https://dl.acm.org/doi/10.1145/3728636},
	doi = {10.1145/3728636},
	abstract = {Efficient compression and tuning techniques have become indispensable in addressing the increasing computational and memory demands of large language models (LLMs). While these models have demonstrated exceptional performance across a wide range of natural language processing tasks, their growing size and resource requirements pose significant challenges to accessibility and sustainability. This survey systematically reviews state-of-the-art methods in model compression, including compression techniques such as knowledge distillation, low-rank approximation, parameter pruning, and quantization, as well as tuning techniques such as parameter-efficient fine-tuning and inference optimization. Compression techniques, though well-established in traditional deep learning, require updated methodologies tailored to the scale and dynamics of LLMs. Simultaneously, parameter-efficient fine-tuning, exemplified by techniques like Low-Rank Adaptation (LoRA) and query tuning, emerges as a promising solution for adapting models with minimal resource overhead. This study provides a detailed taxonomy of these methods, examining their practical applications, strengths, and limitations. Critical gaps are identified in scalability, and the integration of compression and tuning strategies, signaling the need for unified frameworks and hybrid approaches to maximize efficiency and performance. By addressing these challenges, this survey aims at guiding researchers toward sustainable, efficient, and accessible LLM development, ensuring their broader applicability across diverse domains while mitigating resource constraints.},
	number = {10},
	urldate = {2026-01-14},
	journal = {ACM Comput. Surv.},
	author = {Kim, Gun Il and Hwang, Sunga and Jang, Beakcheol},
	month = may,
	year = {2025},
	pages = {253:1--253:39},
	file = {Full Text PDF:files/1212/Kim et al. - 2025 - Efficient Compressing and Tuning Methods for Large Language Models A Systematic Literature Review.pdf:application/pdf},
}

@misc{jin_efficient_2024,
	title = {Efficient {Multimodal} {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Efficient {Multimodal} {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2405.10739},
	doi = {10.48550/arXiv.2405.10739},
	abstract = {In the past year, Multimodal Large Language Models (MLLMs) have demonstrated remarkable performance in tasks such as visual question answering, visual understanding and reasoning. However, the extensive model size and high training and inference costs have hindered the widespread application of MLLMs in academia and industry. Thus, studying efficient and lightweight MLLMs has enormous potential, especially in edge computing scenarios. In this survey, we provide a comprehensive and systematic review of the current state of efficient MLLMs. Specifically, we summarize the timeline of representative efficient MLLMs, research state of efficient structures and strategies, and the applications. Finally, we discuss the limitations of current efficient MLLM research and promising future directions. Please refer to our GitHub repository for more details: https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.},
	urldate = {2026-01-14},
	publisher = {arXiv},
	author = {Jin, Yizhang and Li, Jian and Liu, Yexin and Gu, Tianjun and Wu, Kai and Jiang, Zhengkai and He, Muyang and Zhao, Bo and Tan, Xin and Gan, Zhenye and Wang, Yabiao and Wang, Chengjie and Ma, Lizhuang},
	month = aug,
	year = {2024},
	note = {arXiv:2405.10739 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:files/1213/Jin et al. - 2024 - Efficient Multimodal Large Language Models A Survey.pdf:application/pdf;Snapshot:files/1214/2405.html:text/html},
}

@article{sun_review_2025,
	title = {A review of {AI} edge devices and lightweight {CNN} and {LLM} deployment},
	volume = {614},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231224015625},
	doi = {10.1016/j.neucom.2024.128791},
	abstract = {Artificial Intelligence of Things (AIoT) which integrates artificial intelligence (AI) and the Internet of Things (IoT), has attracted increasing attention recently. With the remarkable development of AI, convolutional neural networks (CNN) have achieved great success from research to deployment in many applications. However, deploying complex and state-of-the-art (SOTA) AI models on edge applications is increasingly a big challenge. This paper investigates literature that deploys lightweight CNNs on AI edge devices in practice. We provide a comprehensive analysis of them and many practical suggestions for researchers: how to obtain/design lightweight CNNs, select suitable AI edge devices, and compress and deploy them in practice. Finally, future trends and opportunities are presented, including the deployment of large language models, trustworthy AI and robust deployment.},
	language = {en},
	urldate = {2026-01-14},
	journal = {Neurocomputing},
	author = {Sun, Kailai and Wang, Xinwei and Miao, Xi and Zhao, Qianchuan},
	month = jan,
	year = {2025},
	pages = {128791},
	file = {PDF:files/1215/Sun et al. - 2025 - A review of AI edge devices and lightweight CNN and LLM deployment.pdf:application/pdf},
}

@article{fareed_systematic_2025,
	title = {A systematic review of ethical considerations of large language models in healthcare and medicine},
	volume = {7},
	issn = {2673-253X},
	url = {https://www.frontiersin.org/articles/10.3389/fdgth.2025.1653631/full},
	doi = {10.3389/fdgth.2025.1653631},
	abstract = {The rapid integration of large language models (LLMs) into healthcare offers significant potential for improving diagnosis, treatment planning, and patient engagement. However, it also presents serious ethical challenges that remain incompletely addressed. In this review, we analyzed 27 peer-reviewed studies published between 2017 and 2025 across four major open-access databases using strict eligibility criteria, robust synthesis methods, and established guidelines to explicitly examine the ethical aspects of deploying LLMs in clinical settings. We explore four key aspects, including the main ethical issues arising from the use of LLMs in healthcare, the prevalent model architectures employed in ethical analyses, the healthcare application domains that are most frequently scrutinized, and the publication and bibliographic patterns characterizing this literature. Our synthesis reveals that bias and fairness (
              
                
                  n
                  =
                  7
                
              
              , 25.9\%) are the most frequently discussed concerns, followed by safety, reliability, transparency, accountability, and privacy, and that the GPT family predominates (
              
                
                  n
                  =
                  14
                
              
              , 51.8\%) among examined models. While privacy protection and bias mitigation received notable attention in the literature, no existing review has systematically addressed the comprehensive ethical issues surrounding LLMs. Most previous studies focus narrowly on specific clinical subdomains and lack a comprehensive methodology. As a systematic mapping of open-access literature, this synthesis identifies dominant ethical patterns, but it is not exhaustive of all ethical work on LLMs in healthcare. We also synthesize identified challenges, outline future research directions and include a provisional ethical integration framework to guide clinicians, developers, and policymakers in the responsible integration of LLMs into clinical workflows.},
	language = {en},
	urldate = {2026-01-14},
	journal = {Frontiers in Digital Health},
	author = {Fareed, Muhammad and Fatima, Madeeha and Uddin, Jamal and Ahmed, Adeel and Sattar, Muhammad Awais},
	month = sep,
	year = {2025},
	pages = {1653631},
	file = {PDF:files/1216/Fareed et al. - 2025 - A systematic review of ethical considerations of large language models in healthcare and medicine.pdf:application/pdf},
}

@article{wang_intelligent_2025,
	title = {Intelligent data analysis in edge computing with large language models: applications, challenges, and future directions},
	volume = {7},
	issn = {2624-9898},
	shorttitle = {Intelligent data analysis in edge computing with large language models},
	url = {https://www.frontiersin.org/articles/10.3389/fcomp.2025.1538277/full},
	doi = {10.3389/fcomp.2025.1538277},
	abstract = {Edge computing has emerged as a vital paradigm for processing data near its source, significantly reducing latency and improving data privacy. Simultaneously, large language models (LLMs) such as GPT-4 and BERT have showcased impressive capabilities in data analysis, natural language processing, and decision-making. This survey explores the intersection of these two domains, specifically focusing on the adaptation and optimization of LLMs for data analysis tasks in edge computing environments. We examine the challenges faced by resource-constrained edge devices, including limited computational power, energy efficiency, and network reliability. Additionally, we discuss how recent advancements in model compression, distributed learning, and edge-friendly architectures are addressing these challenges. Through a comprehensive review of the current research, we analyze the applications, challenges, and future directions of deploying LLMs in edge computing. This analysis aims to facilitate intelligent data analysis across various industries, including healthcare, smart cities, and the internet of things.},
	language = {en},
	urldate = {2026-01-14},
	journal = {Frontiers in Computer Science},
	author = {Wang, Xuanzheng and Xu, Zhipeng and Sui, Xingfei},
	month = may,
	year = {2025},
	pages = {1538277},
	file = {PDF:files/1217/Wang et al. - 2025 - Intelligent data analysis in edge computing with large language models applications, challenges, an.pdf:application/pdf},
}

@misc{xu_-device_2024,
	title = {On-{Device} {Language} {Models}: {A} {Comprehensive} {Review}},
	shorttitle = {On-{Device} {Language} {Models}},
	url = {http://arxiv.org/abs/2409.00088},
	doi = {10.48550/arXiv.2409.00088},
	abstract = {The advent of large language models (LLMs) revolutionized natural language processing applications, and running LLMs on edge devices has become increasingly attractive for reasons including reduced latency, data localization, and personalized user experiences. This comprehensive review examines the challenges of deploying computationally expensive LLMs on resource-constrained devices and explores innovative solutions across multiple domains. The paper investigates the development of on-device language models, their efficient architectures, including parameter sharing and modular designs, as well as state-of-the-art compression techniques like quantization, pruning, and knowledge distillation. Hardware acceleration strategies and collaborative edge-cloud deployment approaches are analyzed, highlighting the intricate balance between performance and resource utilization. Case studies of on-device language models from major mobile manufacturers demonstrate real-world applications and potential benefits. The review also addresses critical aspects such as adaptive learning, multi-modal capabilities, and personalization. By identifying key research directions and open challenges, this paper provides a roadmap for future advancements in on-device language models, emphasizing the need for interdisciplinary efforts to realize the full potential of ubiquitous, intelligent computing while ensuring responsible and ethical deployment. For a comprehensive review of research work and educational resources on on-device large language models (LLMs), please visit https://github.com/NexaAI/Awesome-LLMs-on-device. To download and run on-device LLMs, visit https://www.nexaai.com/models.},
	urldate = {2026-01-14},
	publisher = {arXiv},
	author = {Xu, Jiajun and Li, Zhiyuan and Chen, Wei and Wang, Qun and Gao, Xin and Cai, Qi and Ling, Ziyuan},
	month = sep,
	year = {2024},
	note = {arXiv:2409.00088 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 38 pages, 6 figures},
	file = {Full Text PDF:files/1219/Xu et al. - 2024 - On-Device Language Models A Comprehensive Review.pdf:application/pdf;Snapshot:files/1218/2409.html:text/html},
}

@article{friha_llm-based_2024,
	title = {{LLM}-{Based} {Edge} {Intelligence}: {A} {Comprehensive} {Survey} on {Architectures}, {Applications}, {Security} and {Trustworthiness}},
	volume = {5},
	issn = {2644-125X},
	shorttitle = {{LLM}-{Based} {Edge} {Intelligence}},
	url = {https://ieeexplore.ieee.org/document/10669603/},
	doi = {10.1109/OJCOMS.2024.3456549},
	abstract = {The integration of Large Language Models (LLMs) and Edge Intelligence (EI) introduces a groundbreaking paradigm for intelligent edge devices. With their capacity for human-like language processing and generation, LLMs empower edge computing with a powerful set of tools, paving the way for a new era of decentralized intelligence. Yet, a notable research gap exists in obtaining a thorough comprehension of LLM-based EI architectures, which should incorporate crucial elements such as security, optimization, and responsible development. This survey aims to bridge this gap by providing a comprehensive resource for both researchers and practitioners. We explore LLM-based EI architectures in-depth, carefully analyzing state-of-the-art paradigms and design decisions. To facilitate efficient and scalable edge deployments, we perform a comparative analysis of recent optimization and autonomy techniques specifically designed for resource-constrained edge environments. Additionally, we shed light on the extensive potential of LLM-based EI by demonstrating its varied practical applications across a wide range of domains. Acknowledging the utmost importance of security, our survey thoroughly investigates potential vulnerabilities inherent in LLM-based EI deployments. We explore corresponding defense mechanisms to protect the integrity and confidentiality of data processed at the edge. In conclusion, highlighting the essential aspect of trustworthiness, we outline best practices and guiding principles for the responsible development and deployment of these systems. By conducting a comprehensive review of these key components, our survey aims to support the ethical development and strategic implementation of LLM-driven EI, paving the way for its transformative impact on diverse applications.},
	urldate = {2026-01-14},
	journal = {IEEE Open Journal of the Communications Society},
	author = {Friha, Othmane and Amine Ferrag, Mohamed and Kantarci, Burak and Cakmak, Burak and Ozgun, Arda and Ghoualmi-Zine, Nassira},
	year = {2024},
	keywords = {Robot sensing systems, Real-time systems, Computational modeling, Surveys, Technological innovation, Artificial intelligence, Security, generative AI, large language models (LLMs), security, Edge intelligence (EI), privacy, responsible AI, trustworthiness},
	pages = {5799--5856},
	file = {Full Text PDF:files/1221/Friha et al. - 2024 - LLM-Based Edge Intelligence A Comprehensive Survey on Architectures, Applications, Security and Tru.pdf:application/pdf},
}

@article{zhang_edgeshard_2025,
	title = {{EdgeShard}: {Efficient} {LLM} {Inference} via {Collaborative} {Edge} {Computing}},
	volume = {12},
	issn = {2327-4662},
	shorttitle = {{EdgeShard}},
	url = {https://ieeexplore.ieee.org/document/10818760/},
	doi = {10.1109/JIOT.2024.3524255},
	abstract = {Large language models (LLMs) have shown great success in content generation and intelligent intelligent decision making for IoT systems. Traditionally, LLMs are deployed on the cloud, incurring prolonged latency, high bandwidth costs, and privacy concerns. More recently, edge computing has been considered promising in addressing such concerns because the edge devices are closer to data sources. However, edge devices are cursed by their limited resources and can hardly afford LLMs. Existing studies address such a limitation by offloading heavy workloads from edge to cloud or compressing LLMs via model quantization. These methods either still rely heavily on the remote cloud or suffer substantial accuracy loss. This work is the first to deploy LLMs on a collaborative edge computing environment, in which edge devices and cloud servers share resources and collaborate to infer LLMs with high efficiency and no accuracy loss. We design EdgeShard, a novel approach to partition a computation-intensive LLM into affordable shards and deploy them on distributed devices. The partition and distribution are nontrivial, considering device heterogeneity, bandwidth limitations, and model complexity. To this end, we formulate an adaptive joint device selection and model partition problem and design an efficient dynamic programming algorithm to optimize the inference latency and throughput. Extensive experiments of the popular Llama2 serial models on a real-world testbed reveal that EdgeShard achieves up to 50\% latency reduction and 2 {\textbackslash}times throughput improvement over the state-of-the-art.},
	number = {10},
	urldate = {2026-01-09},
	journal = {IEEE Internet of Things Journal},
	author = {Zhang, Mingjin and Shen, Xiaoming and Cao, Jiannong and Cui, Zeyang and Jiang, Shan},
	month = may,
	year = {2025},
	keywords = {Computational modeling, Optimization, Edge computing, Performance evaluation, Load modeling, Cloud computing, Bandwidth, Memory management, Servers, Collaboration, large language models (LLMs), edge computing, Cloud-edge-end Collaboration, edge artificial intelligence (AI)},
	pages = {13119--13131},
	file = {Full Text PDF:files/1224/Zhang et al. - 2025 - EdgeShard Efficient LLM Inference via Collaborative Edge Computing.pdf:application/pdf},
}
